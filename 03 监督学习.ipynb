{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 3 监督学习\n",
    "## 3.1 分类 & 回归\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 线性模型\n",
    "## 3.2 线性和二次判别分析\n",
    "## 3.3 内核岭回归\n",
    "## 3.4 支持向量机\n",
    "## 3.5 随机梯度下降法\n",
    "## 3.6 最近的邻居\n",
    "## 3.7 高斯过程\n",
    "## 3.8 横向分解\n",
    "## 3.9 朴素贝叶斯\n",
    "## 3.10 决策树\n",
    "## 3.11 整体方法\n",
    "## 3.12 多类和多输出算法\n",
    "## 3.13 特征选择\n",
    "## 3.14 Semi-supervised学习\n",
    "## 3.15 等张回归\n",
    "## 3.16 概率校准\n",
    "## 3.17 神经网络模型(监督)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "回归：预测连续值\n",
    "所以我们如何解决这些问题？\n",
    "线性回归（普通最小二乘）\n",
    "梯度下降：习得参数\n",
    "过拟合\n",
    "这就完成了\n",
    "练习材料和扩展阅读\n",
    "2.1a 线性回归\n",
    "2.1b 实现梯度下降"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}