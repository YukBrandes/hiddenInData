# 3 监督学习
监督学习的目标是通过构建自变量与因变量间关系的拟合模型，解释数据的规律性，以便预测未来的结果；即：当 $y$ 已知时，求解函数 $F$ ，使 $y = F(x)$。现实情境中相等很难，尽可能拟合训练数据中大多数 $y$ 点。
## 3.1 类别划分
一、根据 $y$ 的差异：
- **回归**：$y$ 无限集
- **分类**：$y$ 有限集

多数监督学习算法都同时支持回归与分类问题。其中，分类问题可再分为二分类与多分类问题。部分算法（如随机森林、朴素贝叶斯等）同时支持处理上述情况；但也存在严格的二分类器（线性分类器、SVM等），此时为拓展至多分类场景可使用策略如下：
1. **一对所有（OvA）**：创建与类别数目相等的 $N$ 个分类器，单个分类器训练时，仅选取单一类别为正例其余均为负例，决策时选取决策分数最高的分类器所对应的类。
2. **一对一（OvO）**：将类别数量 $N$ 两两配对作为训练子集单独训练二分类器，共计训练 $\frac{N*(N-1)}{2}$ 个分类器，决策时选出全部分类器中胜出最多的类（比如投票机制）。

二、根据 $F$ 的差异划分：
- **参数模型**：数据服从某分布（$F$），求解待定参数，如线性回归、逻辑回归、感知机等。
- **非参数模型**：数据分布存在但不可知（参数及其数量可变），只能通过非参数统计的方法进行推断，如knn、决策树、朴素贝叶斯、支持向量机、神经网络等。
## 3.2 参数模型
由于参数模型的种类很多，所以将聚焦损失函数与寻解算法进行探讨。
### 3.2.1 回归的损失函数
损失函数，即模型达成的目标，回归的目标是样本中的多数预测值 $\hat y$ 与真值 $y$ 越接近越好（最佳情况一摸一样），即：
$$ MBE(平均偏差误差) = \frac{1}{n}\sum_{i = 1}^n(y_i - \hat y_i),n为记录数 $$
从公式中不难发现，MBE会受到误差方向的影响，产生正负相互抵消，应改良为：
$$ MAE(平均绝对值误差,L1Loss) = \frac{1}{n}\sum_{i = 1}^n|y_i - \hat y_i| $$
MAE虽然改善了正负偏差相互抵消的问题，但是函数在零点不可导，为后续寻找全局最优解造成了困扰，再次优化为：
$$ RMSE(均方根误差,L2Loss) = \sqrt {MSE(均方误差)} = \sqrt {\frac{1}{n}\sum_{i = 1}^n(y_i - \hat y_i)^2} $$
本身应该现有MSE，再优化为RMSE，此处一步到位。RMSE函数具有处处可导的特性，相比于MSE数值量级又下降很多，使其成为了最常使用的回归问题损失函数。函数的指数特性让其对离群点极其敏感，离群点存在时，会刻意牺牲对正常点的优化，着重优化贡献更高的离群点，所以需多加注意。

改良方案有：
$$ HuberLoss(平滑绝对误差) = \sum_{i=1}^n \begin{cases} \frac{1}{2}(y_i - \hat y_i)^2 & |y_i - \hat y_i|<\delta \\ \delta * (|y_i - \hat y_i|-0.5 \delta ^2) & else \end{cases}$$
$\delta$ 最常用的取值为1：
$$ smooth_{L1}(\delta = 1) = \sum_{i=1}^n \begin{cases} 0.5*(y_i - \hat y_i)^2 & |y_i - \hat y_i|<1 \\ |y_i - \hat y_i|-0.5 & else \end{cases} $$
或者：
$$ LogCoshLoss = \sum_{i=1}^n log(cosh(y_i - \hat y_i)) $$
对于较小的 $x$，$log(cosh(x))$ 近似于 $\frac{1}{2}x^2$，对于较大的 $x$，近似于$|x|-log(2)$，具有Huber loss所有的优点同时满足二阶导数处处可微；但也存在误差极大时一阶导数为定值的问题。

最后介绍具有特定适用场景的分位数损失函数：
$$ QuantileLoss = \sum_{y_i<\hat y_i}(1-\lambda)|y_i-\hat y_i| + \sum_{y_i\geq\hat y_i}\lambda|y_i - \hat y_i|, \lambda \in [0,1] $$
通过对正反误差的重视程度，对分位值（$\lambda$）给予不同的惩罚，产生中值偏移，偏重部分区间的拟合精度。

以上仅是我熟识的损失函数，尚有诸多并未提及，亦可根据实际情景自定义损失函数。
### 3.2.2 分类的损失函数
使用RMSE函数及其相关变体理论上是可以的，但分类模型本身函数（如符号函数嵌套线性函数）结构复杂造成RMSE函数存在密集的局部最优解，难以寻找全局最优解，故下面介绍些适合分类问题的损失函数。
#### 3.2.2.1 负似然对数
负似然对数，即**似然函数**取对数后的负值，以二分类问题为例：

1. 假设事件有且仅有互斥的正反两种结果；正例记为1，负例记为0。
2. 假设事件正例发生的概率为：$p$，则反例概率为：$1-p$。
3. 对事件累计实验 $N$ 次，其中正例 $m$ 次，反例 $n$ 次。

则 $N$ 次实验发生上述结果的似然率为：$L(p)=p^m*(1-p)^n$（实验结果存在有序性，如无序数据则为：$L(p)=C^m_N*p^m*(1-p)^n$）这就是似然函数，表征事件发生的可能性。

接着将 $p$ 替换为模型 $h_\theta(x)$ 的预测结果，得：
$$ p(\theta) = \begin{cases} h_\theta(x) & y=1 \\ 1-h_\theta(x) & y=0 \end{cases} = h_\theta(x)^y(1-h_\theta(x))^{(1-y)} $$
将 $p(\theta)$ 代入似然函数，得：
$$ L(\theta) = \prod_{i=1}^n h_\theta(x)^{y_i}(1-h_\theta(x))^{(1-y_i)},y_i代表第i个记录对应的y的真值 $$
依据频率学派观点，充分多的已知事件结果发生，那么此种情况的似然率应最高，故使 $L(p)$ 取最大值的 $\hat p$ 便是 $p$。这样就将求解函数参数的问题等价于寻找合适的 $\theta$ 使似然函数取最大值的问题，其对应的负似然函数就是求解最小值，可作损失函数：
$$ cost(\theta) = -L(\theta) = - \prod_{i=1}^n h_\theta(x)^{y_i}(1-h_\theta(x))^{(1-y_i)} $$
对上式直接求导颇为复杂，引入对数（降低计算复杂度且不改变单调性及最小值取值点）：
$$ cost(\theta) = -lnL(\theta) = - \sum_{i=1}^n y_i * ln(h_\theta(x)) + (1-y_i)*ln(1-h_\theta(x)) $$
矩阵形式为：
$$ cost(\theta) = -Y^T * ln(h_\theta(X))-(E - Y)^T * (E - ln(h_\theta(X))) $$
#### 3.2.2.2 交叉信息熵
因个人水平不足，故粗浅地介绍交叉信息熵(cross entropy)理论，准确信息可查阅相关文档。

**信息**，可以说是一种价值度量。以新闻事件来类比，超出人们想象的、小概率发生的事件才作为头条新闻，因为该新闻的价值高。与之类似，系统中小概率事件蕴含的信息值最高，怎么度量呢？因为信息起源于计算机对信息的记录，只有0/1两种标记方案，故最优策略总是优先存储最可能发生的结果，因为使用频次最高，此后存储的记录发生概率依次递减；在这一准则下，确定某个事件结果发生所消耗的编码长度就是信息，计算公式为：$log_2(\frac{1}{p})$，$p$ 即为某事件的概率（此处我认为$log_n(\frac{1}{p})$,$n$为分叉数）。

**信息熵**：分类系统中多个类别信息值的加权和：$\sum_{i=1}^n p_i * log_2(\frac{1}{p_i})$。

**交叉熵**：基于模型预测的事件概率分布$q_i$的信息加权和：$\sum_{i=1}^n p_i * log_2(\frac{1}{q_i})$。

**相对熵**：相对熵 = 交叉熵 - 信息熵，即：$\sum_{i=1}^n p_i * log_2(\frac{p_i}{q_i})$

相对熵越小表示预测分类与真实分类越接近，故可作损失函数：
$$cost(\theta) = \sum_{i=1}^n p_i * log_2(\frac{1}{q_i}) - \sum_{i=1}^n p_i * log_2(\frac{1}{p_i}) = -\sum_{i=1}^n p_i * log_2(q_i) + \sum_{i=1}^n p_i * log_2(p_i)$$
将 $h_\theta(x)$ 带入公式并截去常数项 $\sum_{i=1}^n p_i * log_2(p_i)$，得：
$$ cost(\theta) = -\sum_{i=1}^n p_i * log_2(q_i) = -\sum_{i=1}^n p_i * [y_i * log_2(h_\theta(x)) + (1-y_i) * log_2(1 - h_\theta(x))] $$
*经实验枚举，仅当 $p_i=q_i$ 时，$- \sum_{i=1}^n p_i log_2(\frac{1}{q_i})$ 最小，具体证明还不会。*
#### 3.2.2.3 指数损失(exponential loss)
*尚未研究，adaboost的损失函数*
#### 3.2.2.4 Hinger损失
*尚未研究，感知机/支持向量机的损失函数*
#### 3.2.2.5 铰链损失
*尚未研究*

### 3.2.3 寻解算法
**最小二乘法（OLS）**：亦称最小平方法，通过寻找模型的最佳参数值使RMSE函数值最小。求解最小二乘法的方法有**矩阵解法**和**梯度下降法**。

*以前以为最小二乘法和梯度下降法是两个方法，其实梯度下降法只是最小二乘法的解法之一。*
#### 3.2.3.1 矩阵解法
为方便后续讲解，设定前提假设如下：
- **模型假设**：$F(x)=a_1*x_1+a_2*x_2+……+a_n*x_n+b=[x_1,x_2,……,x_n,1] \cdot [a_1,a_2,……,a_n,b]^T=XA$
- **损失函数**：$L(x,a)=\frac{1}{2n}\sum_{i=1}^n[(a_1*x_{i1}+a_2*x_{i2}+……+a_n*x_{in}+b)-y_i]^2=\frac{1}{2n}(XA-Y)^T(XA-Y)$

依假设，当损失函数的一阶偏导数（$\partial A$）为零时，损失函数取最小值，即：
$$ \frac{\partial L}{\partial A}=\frac{\partial L}{\partial a_1}+\frac{\partial L}{\partial a_2}+……+\frac{\partial L}{\partial a_n}=\frac{1}{n}\sum_{i=1}^n(a_1x_{i1}+a_2x_{i2}+……+a_nx_{in}+b-y_i)*(x_{i1}+x_{i2}+……+x_{in})=\frac{X^T(XA-Y)}{n}=0 $$
求解：
$$ A = (X^TX)^{-1}X^TY $$
以上的推导过程表明矩阵解法有如下限制：
1. 矩阵 $X$ 必须存在逆矩阵，对于矩阵不可逆的情况多采用舍弃边缘特征的方法。
2. 矩阵 $X$ 的求逆过程的耗时受矩阵规模影响，发生维度灾难时多采用降维处理的方法。
3. 模型假设若非线性，求解将十分复杂或难以开展，此时多采用核函数等转线性关系。
#### 3.2.3.2 梯度下降法
梯度下降法是利用梯度逐步迭代模型参数，求解损失函数最小值的方法。
```
想象你和贝爷一起进行丛林探险，露宿山崖边缘，晨间丛林里雾气弥漫，你们选择下至山下的峡谷补充水源。此时，你们各选了一个位置开始下山，你用脚一点点感受被踩踏的岩石，选择合适的落脚点，你总是选择垂直向下（即坡度最陡）的方向下山，重复如此直到最终下到了山脚。
```
梯度下降法的过程与之相似，假设如下：
- **模型假设**：$F(x)=XA$ 并随机初始化 $A$ 中参数。
- **损失函数**：$L(x,a)=\frac{1}{2n}(XA-Y)^T(XA-Y)$。
- **偏导数**：$\frac{\partial L}{\partial A}=\frac{1}{n}X^T(XA-Y)$。
- **梯度下降**：$A=A-\alpha \frac{\partial L}{\partial A},\alpha \in (0,1)$，学习率（$\alpha$）与梯度（$\frac{\partial L}{\partial A}$）共同决定每轮参数的迭代步长。
- **终止条件**：达预设终止条件或损失不可改善。

其中学习率是用户设定值，需注意：
1. 模型训练前特征需缩放，提高 $\alpha$ 作用效果。
2. $\alpha$ 设定过小，耗时严重；设定过大，反复跳跃难收敛。

与矩阵解法中求解一阶导数为零不同，由于训练数据 $X$，随机参数 $A$、学习率 $\alpha$ 均为已知项，其目标是将现有的随机参数不断改善成最优函数的接近值，所以突破了矩阵解法的限制，适用于多种损失函数。示例中虽然只使用了简单的回归问题举例说明，但是分类问题也适用（负似然对数与交叉信息熵的梯度形式：$X^T*(h_\theta(x)-Y)$），亦可推广到更高维，更复杂的损失函数中使用。

梯度下降实际使用时衍生出三种实操方法：
1. **批梯度下降（BGD）**：每轮迭代计算梯度时使用全部训练数据；优点是朝着最小值迭代，缺点是样本值很大时每轮更新速度会很慢。
2. **随机梯度下降（SGD）**：每轮迭代计算梯度时随机抽取一条训练数据；优点是每轮更新速度快，缺点是样本噪点较多时未必朝着极小值方向更新（多轮迭代能保障整体大致朝着极小值方向更新）。
3. **小批量梯度下降（MBGD）**：每轮迭代计算梯度时随机抽取一定比例训练数据；优点是平衡更新梯度方向准确性与更新速度，缺点是batch值较难确定。

随机性可以很好的跳过局部最优值，所以比较推荐使用小批量梯度下降法；对于随机梯度下降较难快速达到最小值问题，可使用逐渐降低学习率改善，这个过程被称为模拟退火。

值得注意的是有些损失函数除了全局最小值外，还存在多个局部最小值，有时可能永远到不了全局最小值。
## 3.3 非参数模型
非参数模型只是数据分布不可知，不代表建模本身没有参数需要调整，我们还是要通过控制推断参数，评估模型拟合情况，进而控制模型的形状、参数数量及其值。
### 3.3.1 knn
knn是一个简单实用、基于实例学习的算法，其原理是：
1. 以选定的建模特征构建多维空间
2. 计算预测数据与样本数据各点间的空间距离
3. 将样本点按距离由近到远排序
4. 挑选前 $k$ 个样本数据点，作为决策基础
5. 将 $k$ 个样本所属类别中多数类作为预测类

算法的核心是 $k$ 的具体数量和距离的测算方法（欧氏距离、曼哈顿距离等），knn受限于需要一定的存储空间保存训练数据，无法给出模型结构，计算耗时长等问题。
### 3.3.2 朴素贝叶斯
朴素贝叶斯是基于概率论的分类方法，基于不同的概率论原理划分为：
- 伯努利实验：注重0-无/1-有，不考虑次数权重，如：词集模型
- 多项式实验：考虑次数权重，如：词袋模型

其核心是**条件概率**、**贝叶斯准则**和**全概率公式**：
- 条件概率：$P(X|Y) = \frac{P(XY)}{P(Y)}$
- 贝叶斯准则：$P(Y|X) = \frac{P(X|Y) * P(Y)}{P(X)}$
- 全概率公式：$P(X) = \sum_{i=1}^n P(X|y_i)P(y_i)$，其中 $P(y_i)$ 互斥且 $\sum_{i=1}^n P(y_i) = 1$
- $P(Y=y_k|X) = \frac{P(X|y_k) * P(y_k)}{\sum_{i=1}^n P(X|y_i)P(y_i)}$，其中 $n$ 代表 $Y$ 可以取值的类别，$y_k$表示其中某类别
- $P(Y=y_k|X)$ 的计算难点是 $P(X|y_k)$
- 朴素贝叶斯假设特征之间相互独立，则 $P(X|y_k) = P(x_1|y_k) * P(x_2|y_k) * …… * P(x_n|y_k)$
- 特征独立性的条件现实中往往很难满足，但通过牺牲准确性换取计算简化，实际效果还是不错的

除了独立性外，$P(x_i|y_k)$ 存在隐患：
1. 局部值为零，影响最终预测结果
2. 局部值极小，计算机最终结果输出零

针对上述问题，解决方案如下：
1. **拉普拉斯变换**：$\frac{N_k+\lambda}{N+O_k \lambda},\lambda \in [0,1]$
2. 对数计算（乘法变加法）：$P(x_1|y_k) * P(x_2|y_k) * …… * P(x_n|y_k) = e^{ln(P(x_1|y_k))+ln(P(x_2|y_k))+……+ln(P(x_n|y_k))}$
### 3.3.3 决策树
决策树是一个具有高度可解释性的模型，基于特征阈值分割数据，每轮分割将原始数据划分为单一类别占比更高的子集，直到子集中分类近乎为单一类别，主流的算法有ID3、C4.5及CART。
#### 3.3.3.1 ID3 & C4.5
ID3和C4.5都是基于信息论进行不纯度（单一类别占比情况）度量的，且C4.5是ID3的改进方法，故先介绍ID3算法。回顾交叉信息熵中信息熵公式：$\sum_{i=1}^n p_i * log_2(\frac{1}{p_i})$，当 $p_i = 0.5$ 时，信息熵取最大值；当 $p_i = 1$ 时，信息熵取最小值0；可作为度量数据集纯净度的指标，ID3算法便是用此理念来评估数据分割后的优劣程度。

以二分类决策树举例，看看ID3算法是怎么实施的：
1. 决策树中某待分裂节点记为：$a_o$，节点中数据记录数记为：$N_o$，信息熵记为：$-\sum_{i=1}^n p_{oi} * log(P_{oi}),n为类别数量$。
2. 待分裂节点分裂后的左支子节点记为：$a_l$，节点中数据记录数记为：$N_l$，信息熵记为：$-\sum_{i=1}^n p_{li} * log(P_{li}),n为类别数量$。
3. 待分裂节点分裂后的右支子节点记为：$a_r$，节点中数据记录数记为：$N_r$，信息熵记为：$-\sum_{i=1}^n p_{ri} * log(P_{ri}),n为类别数量$。
4. 迭代各个特征及其阈值记录分裂前后系统信息熵的差异：$-\sum_{i=1}^n p_{oi} * log(P_{oi}) - (-\frac{N_l}{N_o}\sum_{i=1}^n p_{li} * log(P_{li})) - (-\frac{N_r}{N_o}\sum_{i=1}^n p_{ri} * log(P_{ri}))$，称作信息增益。
5. 选取信息增益最大的特征及其阈值作为分割节点的规则，分割决策树。
6. 将新分割的节点循环1-5步骤，直至特征使用完毕或者决策树无法再次进行分割。

ID3算法存在几个缺陷：
1. 信息增益对数据可取值较多的特征有偏好，类似“编号”其信息增益接近于1。
2. 没有剪枝策略，模型容易过拟合。
3. 算法本身没有二分叉树的假设，可以多分叉。
4. 连续值、缺失值处理问题。

针对问题1，C4.5作为ID3的改进算法，一定程度上缓解了信息增益受可取值数量的影响，引入“属性熵”的概念。所谓“属性熵”是将子节点看作系统整体，每个节点看作不同的分类，如ID3的示例中 $a_l$ 与 $a_r$ 的“属性熵”为：$-\frac{N_l}{N_o}*log(\frac{N_l}{N_o}) + (-\frac{N_r}{N_o}*log(\frac{N_r}{N_o}) )$，那么C4.5就将原来ID3中信息增益作为判断分裂特征及其阈值选择的评价标准转换为：$\frac{信息增益}{属性熵}$，称作信息增益率。

针对问题2，主要分为**预剪枝**与**后剪枝**两种方法；预剪枝通过每次分裂时判断分裂后是否能提升分类效果（比如通过比较测试集分裂后的性能、损失函数降低比例等）或满足阈值限制（比如树的深度、样本比例等）以决定是否分裂；后剪枝是先将全部特征分裂完毕（或达到限制条件），再从叶子节点至下而上进行剪枝（比较减枝后测试集的性能）的过程；故决策树剪枝常搭配交叉验证。

针对问题3，限定采用二叉树就能解决，其中连续数值通过阈值左右两侧切分数据；离散值通过不同的值组合位于左右两枝。针对问题4中连续值的处理，通过离散化解决，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点。

针对问题4中缺失值的处理可以分为两个子问题：
1. 在特征值缺失的情况下如何进行特征的选择？如果缺失比例较高，直接删除特征；缺失比例可接受，以不含缺失样本子集的信息增益率（或信息增益）乘以子集所占样本比例来评估。
2. 基于无缺失子集选定划分特征后如何处理缺失值样本所属分枝？将含缺失值的样本按照无缺失样本叶子节点占无缺失样本比例划分到子节点中。

当然以上处理方法会影响含缺失数据记录预测时的分类归属，尤其是实际应用中每次都是单一记录预测的情况，故建议在建模前先进行缺失处理。
#### 3.3.3.2 CART
CART算法整体与C4.5相仿，不同点有二：
1. 本身就是二叉树分裂形式
2. 使用基尼系数（不同于经济领域，截取了熵的泰勒展开项，称作基尼不纯度也许容易区分）：$Gini(p) = \sum_{i=1}^np_i*(1-p_i) = 1-\sum_{i=1}^np_i^2,n为类别数量$
#### 3.3.3.3 决策树处理回归问题
分类是寻求叶子节点中的单一类别占比最大化；回归则是寻求叶子节点中的各数据点相近，即与均值的偏差最小化，故采用平均方差（$\frac{1}{n}\sum_{i=1}^n(y_i-E(Y))^2$）替代信息增益，分裂后各节点均方差最小，所有分裂节点均方差和也最小。
### 3.3.4 支持向量机
![](https://static.sitestack.cn/projects/Vay-keen-Machine-learning-learning-notes/3512bde89ff2142d20042e6e809cef36.png)

如图所示，支持向量机（SVM）是在数据样本的空间中找到一个最大的分割平面，由于多数数据很难绝对分割（硬分割），故多使用软分割，允许一定的误分类存在。其数学原理较晦涩，不展开；值得注意的是SVM模型有两个非常重要的参数 $C$（惩罚系数）与 $gamma$：
- $C$ 是对误差的宽容度，影响泛化能力。$C$ 值越高说明越不能容忍出现误差，容易过拟合；$C$ 值越小容易欠拟合。
- $gamma$ 是选择RBF函数作为核函数后自带的一个参数，决定了数据映射到新特征空间后的分布，$gamma$ 值越大支持向量越少，训练与预测的速度越快。

## 3.4 评估模型
### 3.4.1 回归的评估
与损失函数相同，衡量预测值与真实值偏差，使用均方根误差：
$$ RMSE = \sqrt {\frac{1}{n}\sum_{i = 1}^n(y_i - \hat y_i)^2} $$
### 3.4.2 分类的评估
#### 3.4.2.1 二分类
精确率(precision),召回率(Recall)与特异性(specificity)

#### 3.4.2.2 多分类

## 3.5 交叉验证
交叉验证，顾名思义，就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”；然后用训练集来训练模型，用测试集来评估模型预测的好坏是谓“验证”。

交叉验证的主要有如下几种：
1. 简单交叉验证：首先，随机的将样本数据分为两分，然后用训练集来训练模型，在测试集上验证模型；接着把样本打乱，按相同比例重新选择训练集和测试集，继续训练和验证模型；最后选择损失函数评估最优的模型及其参数。　
2. S折交叉验证（S-Folder Cross Validation）：将样本数据随机分成S份，每次随机选择S-1份作为训练集，剩下的1份做测试集；一轮结束后，重新随机选择S-1份做为训练数据；若干轮（小于S）后，选择损失函数评估最优的模型及其参数。
3. 留一交叉验证（Leave-one-out Cross Validation）：S折交叉验证的特例，适用于样本量非常少（$N<50$）的情况，此时S等于样本数 $N$，每次选择 $N-1$ 个样本来训练数据，留一个样本来验证模型预测的好坏。
4. 自助法(bootstrapping)：适用于样本量极少（$N<20$）的情况，每次在 $N$ 样本中随机采集一个样本放入训练集，采样完后把样本放回再重复采集 $N$ 次，得到 $N$ 个样本组成的训练集（很有可能有重复的样本），用没有被采样到的样本做测试集。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差。

通过交叉验证我们可以选择损失函数和模型性能最优的模型与参数组合，当模型确定时，该方法可以配合网格搜索选取最优参数。