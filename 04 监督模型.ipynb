{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('Program': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "9b02d228b0deb9bd5deb88192194232067fb7f0761ef8eded4fa6ac3b1d9be68"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 4 sklearn监督学习\n",
    "## 4.1 广义线性模型\n",
    "### 4.1.1 普通最小二乘法\n",
    "处理[回归问题](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD)，对特征有**非奇异性**（满秩、特征比数多）与**中心化/标准化**要求。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "msd = pd.read_table('data/YearPredictionMSD.txt',sep=',',header=None)\n",
    "msd.columns = [['y'] + ['x' + str(i) for i in range(1,91)]]\n",
    "train = msd.iloc[:463715,:]\n",
    "test = msd.iloc[463715:,:]\n",
    "x_train,y_train,x_test,y_test = train.iloc[:,1:],train[['y']],test.iloc[:,1:],test[['y']]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集R-square:0.24\n测试集R-square:0.23\n"
     ]
    }
   ],
   "source": [
    "# print('参数:%s' % reg.get_params())\n",
    "# print('秩:%s\\n奇异矩阵:\\n%s' % (reg.rank_,reg.singular_))\n",
    "# print('系数:\\n%s\\n截距项:%s' % (reg.coef_,reg.intercept_))\n",
    "print('训练集R-square:%s\\n测试集R-square:%s' % (round(reg.score(x_train,y_train),2),round(reg.score(x_test,y_test),2)))\n"
   ]
  },
  {
   "source": [
    "### 4.1.2 岭回归与分类\n",
    "#### 4.1.2.1 岭回归\n",
    "岭回归通过对系数的大小施加惩罚来解决普通最小二乘法对共线性敏感的问题，其最小化的是带L2正则化的残差平方和，L2正则系数 $\\alpha$ 值越大，收缩量越大，对共线性的鲁棒性也越强。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集R-square:0.24\n测试集R-square:0.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ridge = linear_model.Ridge(alpha=10000.0, # 数值越大，惩罚越大\n",
    "                           tol=0.001, # 预测精度\n",
    "                           solver='auto', # auto,svd,cholesky,lsqr,sparse_cg,sag,saga\n",
    "                           max_iter=None, # 共轭函数求解迭代次数,sparse_cg and lsqr\n",
    "                           random_state=None) # 控制sag、saga\n",
    "ridge.fit(x_train,y_train)\n",
    "# print('参数:%s' % ridge.get_params())\n",
    "# print('系数:\\n%s\\n截距项:%s' % (ridge.coef_,ridge.intercept_))\n",
    "print('训练集R-square:%s\\n测试集R-square:%s' % (round(ridge.score(x_train,y_train),2),round(ridge.score(x_test,y_test),2)))"
   ]
  },
  {
   "source": [
    "由于岭回归对共线性的改善，所以可以使用岭迹图来判断是否剔除某参数以避免共线性。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef,alpha = [],[]\n",
    "for i in np.arange(0,100,1):\n",
    "    ridge = linear_model.Ridge(alpha=i)\n",
    "    ridge.fit(x_train,y_train)\n",
    "    coef.append(pd.DataFrame(ridge.coef_))\n",
    "    alpha.append(i)\n",
    "coef = pd.concat(coef,axis=0).reset_index(drop=True)\n",
    "coef.columns = ['x' + str(i) for i in range(1,91)]\n",
    "alpha = pd.DataFrame({'alpha':alpha})\n",
    "alpha_coef = pd.concat([alpha,coef],axis=1)"
   ]
  },
  {
   "source": [
    "ridge提供了便捷的交叉验证建模函数，进行快速定位："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9.5"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "ridgeCV = linear_model.RidgeCV(alphas=np.arange(0,10,0.5),\n",
    "                               cv=5, # None：留一交叉验证，int：指定折叠数\n",
    "                               scoring='r2') # 评估函数\n",
    "ridgeCV.fit(x_train,y_train)\n",
    "ridgeCV.alpha_ # ridgeCV.best_score_,ridgeCV.coef_,ridgeCV.intercept_"
   ]
  },
  {
   "source": [
    "#### 4.1.2.2 岭分类\n",
    "适用于[二分类问题](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)，模型将类别转换为 $-1,1$ 两种标签，然后使用回归的方式计算。                                              "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train accuracy:0.69,test accuracy:0.68.\ntrain auc:0.67,test auc:0.67.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "data = pd.read_csv('data/default of credit card clients.csv')\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.iloc[:,1:],data['default payment next month'],test_size=0.3,random_state=11)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "ridgeClassiflier = linear_model.RidgeClassifier(alpha=0.1,\n",
    "                                                tol=0.01,\n",
    "                                                # slover='auto',\n",
    "                                                # max_iter=None,\n",
    "                                                # random_state=None,\n",
    "                                                class_weight='balanced') # dict,balanced\n",
    "ridgeClassiflier.fit(x_train,y_train)\n",
    "print('train accuracy:%s,test accuracy:%s.' % (round(ridgeClassiflier.score(x_train,y_train),2),round(ridgeClassiflier.score(x_test,y_test),2))) \n",
    "print('train auc:%s,test auc:%s.' % (round(roc_auc_score(y_train,ridgeClassiflier.predict(x_train)),2),round(roc_auc_score(y_test,ridgeClassiflier.predict(x_test)),2)))"
   ]
  },
  {
   "source": [
    "也有与之相匹配的快速交叉验证方法："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best alpha:678,best score:0.72.\n"
     ]
    }
   ],
   "source": [
    "ridgeClassiflierCV = linear_model.RidgeClassifierCV(alphas=range(670,680,1),\n",
    "                                                    cv=3,\n",
    "                                                    scoring='roc_auc',\n",
    "                                                    class_weight='balanced')\n",
    "ridgeClassiflierCV.fit(x_train,y_train)\n",
    "print('best alpha:%s,best score:%s.' % (round(ridgeClassiflierCV.alpha_,2),round(ridgeClassiflierCV.best_score_,2)))"
   ]
  },
  {
   "source": [
    "### 4.1.3 Lasso\n",
    "Lasso通过最小化L1正则化的残差平方和，快速提取出重要变量，简化模型（使用LASSO回归系数轨迹）。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train R-square:0.24\ntest R-square:0.23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing,linear_model\n",
    "msd = pd.read_table('data/YearPredictionMSD.txt',sep=',',header=None)\n",
    "msd.columns = [['y'] + ['x' + str(i) for i in range(1,91)]]\n",
    "train = msd.iloc[:463715,:]\n",
    "test = msd.iloc[463715:,:]\n",
    "x_train,y_train,x_test,y_test = train.iloc[:,1:],train[['y']],test.iloc[:,1:],test[['y']]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "lasso = linear_model.Lasso(alpha=0.01, # 数值越大，惩罚越大\n",
    "                           tol=0.01,\n",
    "                           precompute=True) # 启用预定义的格拉姆矩阵加速计算\n",
    "lasso.fit(x_train,y_train)\n",
    "print('train R-square:%s\\ntest R-square:%s' % (round(lasso.score(x_train,y_train),2),round(lasso.score(x_test,y_test),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alpha:0.024858764004282215\ntrain R-square:0.24\ntest R-square:0.23\n"
     ]
    }
   ],
   "source": [
    "lassoCV = linear_model.LassoCV(cv=3,\n",
    "eps=0.01,\n",
    "n_alphas=100, # alphas=[0.1,10]\n",
    "tol=0.01)\n",
    "\n",
    "lassoCV.fit(x_train,np.ravel(y_train))\n",
    "print('alpha:%s' % lassoCV.alpha_)\n",
    "print('train R-square:%s\\ntest R-square:%s' % (round(lassoCV.score(x_train,y_train),2),round(lassoCV.score(x_test,y_test),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alpha:9.502802568068557e-06\ntrain R-square:0.24\ntest R-square:0.23\n"
     ]
    }
   ],
   "source": [
    "lassoLarsCV = linear_model.LassoLarsCV(cv=3,\n",
    "                                       max_n_alphas=1000,\n",
    "                                       eps=2.220446049250313e-16)\n",
    "lassoLarsCV.fit(x_train,np.ravel(y_train))\n",
    "print('alpha:%s' % lassoLarsCV.alpha_)\n",
    "print('train R-square:%s\\ntest R-square:%s' % (round(lassoLarsCV.score(x_train,y_train),2),round(lassoLarsCV.score(x_test,y_test),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alpha:3.1343920992800895e-07\ntrain R-square:0.24\ntest R-square:0.23\n"
     ]
    }
   ],
   "source": [
    "lassoLarsIC = linear_model.LassoLarsIC(criterion='aic') # aic/bic\n",
    "lassoLarsIC.fit(x_train,np.ravel(y_train))\n",
    "print('alpha:%s' % lassoLarsIC.alpha_)\n",
    "print('train R-square:%s\\ntest R-square:%s' % (round(lassoLarsIC.score(x_train,y_train),2),round(lassoLarsIC.score(x_test,y_test),2)))"
   ]
  },
  {
   "source": [
    "与岭回归一样，Lasso也可以进行多任务分类：MultiTaskLasso。\n",
    "### 4.1.4 Logistic回归\n",
    "用于处理二分类问题，lbfgs求解器鲁棒性占优；对于大型数据集，saga求解器通常更快。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train accuracy:0.81,test accuracy:0.81.\ntrain auc:0.72,test auc:0.73.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "data = pd.read_csv('data/default of credit card clients.csv')\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.iloc[:,1:],data['default payment next month'],test_size=0.3,random_state=11)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "lr = linear_model.LogisticRegression(C=10000, # 正则化系数的倒数\n",
    "                                     #class_weight='balanced',\n",
    "                                     penalty='elasticnet', # l1,l2,elasticnet;l1-liblinear\n",
    "                                     solver='saga', # liblinear(坐标轴下降法),lbfgs(loss二阶导),newton-cg(loss二阶导),sag(随机平均梯度下降),saga\n",
    "                                     tol=0.01, # 迭代终止判据的误差范围\n",
    "                                     max_iter=500,\n",
    "                                     random_state=11, # sag,saga,liblinear时\n",
    "                                     l1_ratio=0.9) # 仅在惩罚='elasticnet'时使用；值为0等同于使用惩罚='l2'，值为1等同于使用惩罚='l1'。当0 < l1_ratio <1时，罚点球是L1和L2的组合。\n",
    "\n",
    "lr.fit(x_train,np.ravel(y_train))\n",
    "print('train accuracy:%s,test accuracy:%s.' % (round(lr.score(x_train,y_train),2),round(lr.score(x_test,y_test),2))) \n",
    "print('train auc:%s,test auc:%s.' % (round(roc_auc_score(y_train,lr.predict_proba(x_train)[:,1]),2),round(roc_auc_score(y_test,lr.predict_proba(x_test)[:,1]),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train auc:0.72,test auc:0.73.\nbest C:[10000.],best l1 ratio:[0.9].\n"
     ]
    }
   ],
   "source": [
    "lrCV = linear_model.LogisticRegressionCV(Cs=[0.1,1,10,100,1000,10000],\n",
    "                                         cv=3,\n",
    "                                         #class_weight='balanced',\n",
    "                                         penalty='elasticnet', # l1,l2,elasticnet\n",
    "                                         scoring='roc_auc',\n",
    "                                         solver='saga', # newton-cg,lbfgs,liblinear,sag,saga\n",
    "                                         tol=0.01,\n",
    "                                         max_iter=500,\n",
    "                                         random_state=11,\n",
    "                                         l1_ratios=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "lrCV.fit(x_train,np.ravel(y_train))\n",
    "print('train auc:%s,test auc:%s.' % (round(roc_auc_score(y_train,lrCV.predict_proba(x_train)[:,1]),2),round(roc_auc_score(y_test,lrCV.predict_proba(x_test)[:,1]),2))) # predict,predict_proba,predict_log_proba\n",
    "print('best C:%s,best l1 ratio:%s.' % (lrCV.C_,lrCV.l1_ratio_))"
   ]
  },
  {
   "source": [
    "一点感悟：balanced调参，非balanced训练最终模型，效果比较好。\n",
    "### 4.1.6 随机梯度下降\n",
    "适合大数据集，设定 loss=\"log\" ，则 SGDClassifier 拟合一个逻辑回归模型，而 loss=\"hinge\" 拟合线性支持向量机（SVM）。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51\n0.38784695658444734\n0.3928081903351961\n-0.06634117171935361\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "dt1 = pd.read_csv('data/pp_gas_emission/gt_2011.csv')\n",
    "dt2 = pd.read_csv('data/pp_gas_emission/gt_2012.csv')\n",
    "dt3 = pd.read_csv('data/pp_gas_emission/gt_2013.csv')\n",
    "dt4 = pd.read_csv('data/pp_gas_emission/gt_2014.csv')\n",
    "data = pd.concat([dt1,dt2,dt3,dt4],axis=0).reset_index(drop=True)\n",
    "verify = pd.read_csv('data/pp_gas_emission/gt_2015.csv')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.iloc[:,:9],data.NOX)\n",
    "y_verify = verify.NOX\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "verify = scaler.transform(verify.iloc[:,:9])\n",
    "\n",
    "sgd = linear_model.SGDRegressor(loss='epsilon_insensitive', # squared_loss,huber(对异常不敏感),epsilon_insensitive(超限后线性),squared_epsilon_insensitive\n",
    "                                penalty='elasticnet', # l2,l1,elasticnet\n",
    "                                alpha=0.01, # 值越大，正则化越强;optimal\n",
    "                                l1_ratio=0.5,\n",
    "                                max_iter=100,\n",
    "                                tol=0.01,\n",
    "                                epsilon=0.1, # huber,epsilon_insensitive,squared_epsilon_insensitive 敏感阈值界限\n",
    "                                random_state=11,\n",
    "                                learning_rate='optimal', # constant,optimal,invscaling,adaptive\n",
    "                                eta0=0.1, # 'constant','invscaling','adaptive'的初始化学习率\n",
    "                                # power_t=0.25, # invscaling 所需\n",
    "                                early_stopping=True,\n",
    "                                validation_fraction=0.1, # early_stopping预留验证集比例\n",
    "                                n_iter_no_change=50)\n",
    "sgd.fit(x_train,y_train)\n",
    "print(sgd.n_iter_)\n",
    "print(sgd.score(x_train,y_train)) # mean_squared_error(y_train,sgd.predict(x_train))\n",
    "print(sgd.score(x_test,y_test))\n",
    "print(sgd.score(verify,y_verify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "151\n0.8073809523809524\n0.8023333333333333\n0.68\n0.69\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "data = pd.read_csv('data/default of credit card clients.csv')\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.iloc[:,1:],data['default payment next month'],test_size=0.3,random_state=11)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "sgd = linear_model.SGDClassifier(loss='hinge', # hinge,log,modified_huber,squared_hinge,perceptron;squared_loss,huber,epsilon_insensitive,squared_epsilon_insensitive.\n",
    "                                 penalty='elasticnet',\n",
    "                                 alpha=0.2,\n",
    "                                 l1_ratio=0.2,\n",
    "                                 random_state=11,\n",
    "                                 learning_rate='invscaling',\n",
    "                                 eta0=0.1,\n",
    "                                 power_t=0.4,\n",
    "                                 early_stopping=True,\n",
    "                                 validation_fraction=0.1,\n",
    "                                 n_iter_no_change=100,\n",
    "                                 class_weight='balanced')\n",
    "sgd.fit(x_train,y_train)\n",
    "print(sgd.n_iter_)\n",
    "print(sgd.score(x_train,y_train))\n",
    "print(sgd.score(x_test,y_test))\n",
    "print(round(roc_auc_score(y_train,sgd.predict(x_train)),2))\n",
    "print(round(roc_auc_score(y_test,sgd.predict(x_test)),2))"
   ]
  },
  {
   "source": [
    "### 4.1.7 多项式回归"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = pd.read_table('data/pp_gas_emission/gt_2011.csv',sep=',') # 2011~2015\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.iloc[:,:9],data.CO,random_state=11,test_size=0.3)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "source": [
    "### 4.1.8 稳健回归"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "data = pd.read_csv('data/default of credit card clients.csv')\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.iloc[:,1:],data['default payment next month'],test_size=0.3,random_state=11)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import kernel_ridge\n",
    "kernel_ridge.KernelRidge(alpha=,\n",
    "kernel='linear', # linear,rbf,sigmoid,poly/polynomial,laplacian,cosine,chi2,additive_chi2\n",
    "gamma=, # rbf,laplacian,poly,chi2,sigmoid 核中的参数，使用其他核时无效\n",
    "degree=, # poly核中的参数d，使用其他核时无效。\n",
    "coef0=, # poly和sigmoid核中的0参数的替代值，使用其他核时无效。\n",
    "kernel_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.2 线性和二次判别分析\n",
    "## 4.3 内核岭回归\n",
    "## 4.4 支持向量机\n",
    "## 4.5 随机梯度下降法\n",
    "## 4.6 最近的邻居\n",
    "## 4.7 高斯过程\n",
    "## 4.8 横向分解\n",
    "## 4.9 朴素贝叶斯\n",
    "## 4.10 决策树\n",
    "## 4.11 整体方法\n",
    "## 4.12 多类和多输出算法\n",
    "## 4.13 特征选择\n",
    "## 4.14 Semi-supervised学习\n",
    "## 4.15 等张回归\n",
    "## 4.16 概率校准\n",
    "## 4.17 神经网络模型(监督)\n",
    "\n",
    "## 过拟合"
   ]
  }
 ]
}